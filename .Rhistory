df_test <- df[-splitIndex,]
library(rpart)
tree_model <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 3))
library(rattle)
fancyRpartPlot(tree_model)
tree_model$variable.importance
barplot(tree_model$variable.importance)
pred <- predict(tree_model, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target)
cm$overall[1]
library(caret)
tuneGrid = expand.grid(maxdepth = 2:10)
trControl = trainControl(method = "cv",
number = 5)
tree_approach2 <- train(target~., data=df_train,
method = "rpart2", trControl
=trControl, tuneGrid = tuneGrid)
plot(tree_approach2)
trControl1 = trainControl(method = "cv",
number = 5)
tuneGrid1 = expand.grid(mtry = 2:4,
splitrule = c('gini', 'extratrees'),
min.node.size = c(2:5))
forest_ranger <- train(target~., data=df_train,
method = "ranger",
trControl = trControl1,
tuneGrid = tuneGrid1)
plot(forest_ranger)
plot(forest_ranger)
`
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(haven)
library(tidyverse)
library(dplyr)
#df = read_sas('hdd0318cy.sas7bdat')
df = read_csv('MaseraEmilyMidterm.csv')
df1 = df %>% filter(yod == 18)
df = df1 %>% select("yod", "payfix","pay_ub92","age",
"sex","raceethn","provider","moa",
"yoa","mod","admtype", "asource" ,
"preopday" ,"los", "service" , "icu","ccu",
"dispub92", "payer"  ,"drg","trandb",
"randbg","randbs","orr", "anes","seq",
"lab","dtest", "ther","blood","phar",
"other","patcon","bwght","total","tot" ,
"ecodub92","b_wt","pt_state","diag_adm","ancilar" ,
"campus","er_fee","er_chrg","er_mode","obs_chrg",
"obs_hour","psycchrg","nicu_day")
write_csv(df1, 'MaseraEmilyMidterm.csv' )
colSums(is.na(df1))
df = df %>% select(-payfix, -raceethn, -admtype, -asource, -preopday, -bwght, -ecodub92, -pt_state, -diag_adm, -er_mode, -obs_hour, -nicu_day)
df %>% count(moa) %>% arrange(-n)
##October admitted the most number of patients##
df %>% filter(sex=='1') %>% count(moa) %>% arrange(-n)
##October also admitted the most male patients##
df %>% filter(sex=='2', age>='13'& age<='19') %>%
count(moa) %>% arrange(-n)
## March has the most number of teenage female patients##
df %>% filter(sex=='2', moa=='10') %>% count(provider) %>% arrange(-n)
##provider 7205 has the most number of female patietns in October
df %>% group_by(sex) %>% summarise(average_age = mean(age)) %>% arrange(-average_age)
##Male patients are older on average##
df %>% group_by(moa) %>% summarise(average_age = mean(age)) %>% arrange(-average_age)
##January has the oldest average age##
df %>% group_by(provider) %>% summarise(average_tot = mean(tot)) %>% arrange(-average_tot)
##Provider 7215 has the highest total charge##
df %>% group_by(provider) %>% filter(sex=='1', age>='13'& age<='19') %>% summarise(average_tot = mean(tot)) %>% arrange(average_tot)
##provider 7206 has the least total charge for teenage male on average##
df$season <- case_when(df$moa >=3 & df$moa < 6 ~ 'Spring', df$moa >= 6 & df$moa < 9 ~'Summer', df$moa >=9 & df$moa <12 ~ 'Fall', TRUE ~ 'Winter')
df %>% group_by(season) %>% summarise(average_los = mean(los)) %>% arrange(-average_los)
##Summer has the longest length of stay on average##
df %>%
filter(sex=='1', age=='20', season=='Fall', los=='1') %>%
summarise(average_tot = mean(tot)) %>%
arrange(average_tot)
##On average, a 20 year old male gets charged $16,511 for staying 1 day in the fall season##
library(ggplot2)
library(dplyr)
df$sex = case_when(df$sex == 1 ~ 'Male',
df$sex == 2 ~ 'Female',
TRUE ~ 'Unknown')
df %>% ggplot() + geom_point(mapping=aes(x=age, y=los)) + facet_wrap(~sex) +
labs(x='Age',
y = 'Length of Stay',
title = 'Length of Stay by Age and Sex',
caption = 'Younger people of both genders seem to generally have longer stays than older people. The plots are similar between the two genders.')
df %>% ggplot()+
geom_density(mapping = aes(x = age)) +
labs(x="Age", y="Density", title = "Age Distribution", caption='It is more common that people in their 60s are admitted than any other age range.')
df %>% ggplot()+
geom_bar(mapping = aes(x = campus))+
labs(x="Campus", y="Count", title = "Campus of Patients Distribution", caption='Campus 0 is the most common campus of the patient to be on.')
df %>% ggplot()+
geom_bar(mapping = aes(x = sex))+
labs(x="Sex", y="Count", title = "Sex Distribution", caption="Females are most commonly admitted")
df %>% ggplot()+geom_point(aes(x=age, y=los))+
labs(x="Age", y="Length of Stay", title = "Length of Stay by Age", caption="The average length of stay is typically longer for people around the age of 30")
df %>%
ggplot()+
geom_boxplot(mapping = aes(x = age, y = sex))+
labs(x='Age',
y='Sex',
title='Age Distributions Based on Sex',
caption='A box plot displaying summary statistics for patient age for each sex.')
df %>% ggplot() + geom_point(mapping=aes(x=age, y=tot)) + facet_wrap(~sex) +
labs(x='Age',
y = 'Total Charge',
title = 'Total Charge by Age',
caption = 'Most higher charges occur in very young patients.')
df %>% group_by(sex,age) %>%
summarise(mean_charge = mean(tot)) %>% ggplot() +
geom_col(aes(x=age, y=mean_charge, fill=sex), position = 'dodge') +
labs(x='Age',
y='Average Total Charge',
fill = 'Sex',
title = 'Average Total Charge by Age and Sex',
caption = 'There is a peak in average change at the age of 15, especially for males. The average total charge generally increases until age 70 and then decreases after. And males generally have the highest average total charges for most ages.')
df %>% ggplot()+
geom_bar(mapping = aes(x = provider))+
labs(x="Provider", y="Count", title = "Provider Distribution", caption="The most commonly used provider is Rhode Island Hospital")
df %>% ggplot() + geom_bar(mapping=aes(x=sex, fill=season), position = 'dodge') +
labs(x='Season',
y='Count',
fill = 'Season',
title = 'Count By Season',
caption = 'All seasons admit around the same amount of patients, but spring
admits the most.')
library(gganimate)
df %>% ggplot()+
geom_bar(mapping = aes(x = sex)) + transition_states(age) +
labs(x="Sex", y="Count", title = "Sex Distribution by Age", caption="This show the gender most commonly admitted for each age")
df$target = case_when(df$tot < median(df$tot) ~ 'low',
TRUE ~ 'high')
library(caret)
df <- df %>% filter('raceethn'!='', 'admtype'!='')
df$tot2 <- ifelse(df$tot<median(df$tot),'low', 'high')
df <- df %>%
mutate(target = as.factor(tot2),
sex = as.factor(sex),
raceehtn = as.factor('raceethn'),
campus = as.factor(campus),
moa = as.factor(moa),
mod = as.factor(mod),
admtype=as.factor('admtype'))
df <- df %>%
mutate(age = as.numeric(age),
los = as.numeric(los))
df <- df %>% select('target','age','sex','provider','moa','mod','campus','los')
set.seed(2020)
splitIndex <- createDataPartition(df$target, p = .10, list=FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
library(rpart)
library(rattle)
tree_model <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 3))
library(rattle)
fancyRpartPlot(tree_model)
tree_model$variable.importance
barplot(tree_model$variable.importance)
pred <- predict(tree_model, df_test, type = "class")
cm <- confusionMatrix(data = pred, reference = df_test$target)
cm$overall[1]
library(caret)
tuneGrid = expand.grid(maxdepth = 2:4)
trControl = trainControl(method = "cv",
number = 3)
tree_approach2 <- train(target~., data=df_train,
method = "rpart2", trControl
=trControl, tuneGrid = tuneGrid)
plot(tree_approach2)
trControl1 = trainControl(method = "cv",
number = 3)
tuneGrid1 = expand.grid(mtry = 2:4,
splitrule = c('gini', 'extratrees'),
min.node.size = c(2:5))
forest_ranger <- train(target~., data=df_train,
method = "ranger",
trControl = trControl1,
tuneGrid = tuneGrid1)
plot(forest_ranger)
results <- resamples(list('Decision Tree' = tree_approach2,'Random Forest' = forest_ranger))
bwplot(results)
##Final selection for the model is the tree model##
pred1 <- predict(tree_approach2, df_test)
cm1 <- confusionMatrix(data = pred1, reference = df_test$target)
cm1$overall[1]
df
df$target = case_when(df$los < mean(df$los) ~ 'low',
TRUE ~ 'high')
df$season = case_when(df$moa < 3 ~ 'Winter',
df$moa < 6 ~ 'Spring',
df$moa < 9 ~ 'Summer',
df$moa < 12 ~ 'Fall',
TRUE ~ 'Winter')
df = df %>% select("age","sex","provider","moa","mod", "campus","los","season","target")
df = df %>% filter('raceethn'>=1, 'admtype'>=1)
df$target = as.factor(df$target)
df$season = as.factor(df$season)
df
df$target = case_when(df$los < mean(df$los) ~ 'low',
TRUE ~ 'high')
df$moa = as.numeric(df$moa)
df$season = case_when(df$moa < 3 ~ 'Winter',
df$moa < 6 ~ 'Spring',
df$moa < 9 ~ 'Summer',
df$moa < 12 ~ 'Fall',
TRUE ~ 'Winter')
df = df %>% select("age","sex","provider","moa","mod", "campus","season","target")
df = df %>% filter('raceethn'>=1, 'admtype'>=1)
df$target = as.factor(df$target)
df$season = as.factor(df$season)
splitIndex <- createDataPartition(df$target, p = .10,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
tree_model <- rpart(target ~ ., data = df_train,
control = rpart.control(maxdepth = 3))
fancyRpartPlot(tree_model)
barplot(tree_model$variable.importance)
trControl = trainControl(method = "cv",
number = 5)
tuneGrid = expand.grid(mtry = 2:3,
splitrule = c('gini', 'extratrees'),
min.node.size = c(1:5))
forest_ranger <- train(target~., data=df_train,
method = "ranger",
trControl = trControl,
tuneGrid = tuneGrid)
df$target = case_when(df$los < mean(df$los) ~ 'low',
TRUE ~ 'high')
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(gganimate)
df %>% ggplot()+
geom_bar(mapping = aes(x = sex)) + transition_states(age) +
labs(x="Sex", y="Count", title = "Sex Distribution by Age", caption="This show the gender most commonly admitted for each age")
results <- resamples(list('Decision Tree' = tree_approach2,'Random Forest' = forest_ranger))
results <- resamples(list('Decision Tree' = tree_approach2,'Random Forest' = forest_ranger))
![](plot11.gif){width="80%"}
knitr::opts_chunk$set(message = FALSE)
df$century2 = case_when(df$release_year >= 2000 ~ "21",
df$release_year >= 1950 ~ "second_half_20",
TRUE ~ "first_half_20")
df$century2 = case_when(df$release_year >= 2000 ~ "21",
df$release_year >= 1950 ~ "second_half_20",
TRUE ~ "first_half_20")
knitr::opts_chunk$set(message = FALSE)
library(tidyverse)
library(tidytext)
library(ggplot2)
library(tidyr)
df = read_csv("netflix_titles.csv")
df$century <- ifelse(df$release_year>=2000, '21','20')
df %>% filter(century == 20) %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(century, word, sort = TRUE) %>%
head(10) %>%
ggplot(aes(x = n, y = reorder(word, n))) +
geom_col() +
labs(y = '', x = 'Frequency')
df %>% filter(century == 21) %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(century, word, sort = TRUE) %>%
head(10) %>%
ggplot(aes(x = n, y = reorder(word, n))) +
geom_col() +
labs(y = '', x = 'Frequency')
df %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(century, word, sort = TRUE) %>%
group_by(century) %>%
slice_max(n, n = 10) %>%
ungroup() %>%
mutate(word = reorder_within(word, by = n, within = century)) %>%
ggplot(aes(n, word, fill = century)) +
geom_col(show.legend = FALSE) +
facet_wrap(~century, scales = "free") +
labs(x = "Frequency",
y = NULL)+
scale_y_reordered()
library(wordcloud)
pal <- brewer.pal(8,"Dark2")
df %>%
filter(century=='20') %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(word, sort = TRUE) %>%
with(wordcloud(word, n, random.order = FALSE, max.words = 50, colors=pal))
df %>%
filter(century=='21') %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(word, sort = TRUE) %>%
with(wordcloud(word, n, random.order = FALSE, max.words = 50, colors=pal))
df %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(century, word, sort = TRUE) %>%
group_by(century) %>%
inner_join(get_sentiments("bing")) %>%
filter(!is.na(sentiment)) %>%
count(sentiment, sort = TRUE) %>%
group_by(century) %>%
mutate(n = n/sum(n)) %>%
ggplot(aes(century, n, fill=sentiment))+geom_col(position = 'fill')+
labs(y='Relative Frequency', x ='Century')
##The 21st century has a slightly greater frequency of negative sentiments than the 20th century.##
library(textdata)
df %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(century, word, sort = TRUE) %>%
group_by(century) %>%
inner_join(get_sentiments("nrc")) %>%
filter(!is.na(sentiment)) %>%
count(sentiment, sort = TRUE) %>%
group_by(century) %>%
mutate(n = n/sum(n)) %>%
ggplot(aes(century, n, fill=sentiment))+geom_col(position = 'fill')+
labs(y='Relative Frequency', x ='Century')
#the frequencies are very similar between the two centuries, but the 21st century seems to have less frequency of anger and positive but more negative sentiments overall. ##
df %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(century, word, sort = TRUE) %>%
group_by(century) %>%
inner_join(get_sentiments("afinn")) %>%
mutate(sentiment = value) %>%
filter(!is.na(sentiment)) %>%
count(sentiment, sort = TRUE) %>%
group_by(century) %>%
mutate(n = n/sum(n)) %>%
ggplot(aes(century, n, fill=factor(sentiment)))+geom_col(position = 'dodge')+
labs(y='Relative Frequency', fill = 'Sentiment', x = 'Century')
##This shows the jump in negative sentiments from the 20th to 21st century with a much higher peak at -2.##
library(caret)
library(themis)
library(textrecipes)
df2 <- df %>%
mutate(target = century) %>%
select(target, description)
df2$target = as.factor(df2$target)
a <- recipe(target~description,
data = df2) %>%
step_tokenize(description) %>%
step_tokenfilter(description, max_tokens = 50) %>%
step_tfidf(description) %>%
step_normalize(all_numeric_predictors()) %>%
step_smote(target) %>%
prep()
df2 <- juice(a)
set.seed(2021)
splitIndex <- createDataPartition(df2$target, p = .4,
list = FALSE)
df2_train <- df2[ splitIndex,]
df2_test <- df2[-splitIndex,]
forest_ranger <- train(target~., data=df2_train,
method = "ranger")
library(caret)
library(themis)
library(textrecipes)
df2 <- df %>%
mutate(target = century) %>%
select(target, description)
df2$target = as.factor(df2$target)
a <- recipe(target~description,
data = df2) %>%
step_tokenize(description) %>%
step_tokenfilter(description, max_tokens = 50) %>%
step_tfidf(description) %>%
step_normalize(all_numeric_predictors()) %>%
step_smote(target) %>%
prep()
df2 <- juice(a)
set.seed(2021)
splitIndex <- createDataPartition(df2$target, p = .4,
list = FALSE)
df2_train <- df2[ splitIndex,]
df2_test <- df2[-splitIndex,]
forest_ranger <- train(target~., data=df2_train,
method = "ranger")
knitr::opts_chunk$set(message = FALSE)
df$ratings <- case_when(df$rating %in% c('R','TV-MA')~'Adult', df$rating %in% c('PG-13','TV-PG')~'Teenager', TRUE~'Child')
View(df)
df$rating <- case_when(df$rating %in% c('R','TV-MA')~'Adult', df$rating %in% c('PG-13','TV-PG')~'Teenager', TRUE~'Child')
df$rating <- case_when(df$rating %in% c('R','TV-MA')~'Adult', df$rating %in% c('PG-13','TV-PG')~'Teenager', TRUE~'Child')
df$rating <- case_when(df$rating %in% c('R','TV-MA')~'Adult', df$rating %in% c('PG-13','TV-PG')~'Teenager', TRUE~'Child')
df$rating <- case_when(df$rating %in% c('R','TV-MA')~'Adult', df$rating %in% c('PG-13','TV-PG')~'Teenager', TRUE~'Child')
df$rating <- case_when(df$rating %in% c('R','TV-MA')~'Adult', df$rating %in% c('PG-13','TV-PG')~'Teenager', TRUE~'Child')
df$rating <- case_when(df$rating %in% c('R','TV-MA')~'Adult', df$rating %in% c('PG-13','TV-PG')~'Teenager', TRUE~'Child')
install.package('case_when')
df$century2 = case_when(df$release_year >= 2000 ~ "21",
df$release_year >= 1950 ~ "second_half_20",
TRUE ~ "first_half_20")
library(tidyverse)
library(tidytext)
library(ggplot2)
library(tidyr)
df = read_csv("netflix_titles.csv")
df$century <- ifelse(df$release_year>=2000, '21','20')
df %>% filter(century == 20) %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(century, word, sort = TRUE) %>%
head(10) %>%
ggplot(aes(x = n, y = reorder(word, n))) +
geom_col() +
labs(y = '', x = 'Frequency')
df %>% filter(century == 21) %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(century, word, sort = TRUE) %>%
head(10) %>%
ggplot(aes(x = n, y = reorder(word, n))) +
geom_col() +
labs(y = '', x = 'Frequency')
df %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(century, word, sort = TRUE) %>%
group_by(century) %>%
slice_max(n, n = 10) %>%
ungroup() %>%
mutate(word = reorder_within(word, by = n, within = century)) %>%
ggplot(aes(n, word, fill = century)) +
geom_col(show.legend = FALSE) +
facet_wrap(~century, scales = "free") +
labs(x = "Frequency",
y = NULL)+
scale_y_reordered()
library(wordcloud)
pal <- brewer.pal(8,"Dark2")
df %>%
filter(century=='20') %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(word, sort = TRUE) %>%
with(wordcloud(word, n, random.order = FALSE, max.words = 50, colors=pal))
df %>%
filter(century=='21') %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(word, sort = TRUE) %>%
with(wordcloud(word, n, random.order = FALSE, max.words = 50, colors=pal))
df %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(century, word, sort = TRUE) %>%
group_by(century) %>%
inner_join(get_sentiments("bing")) %>%
filter(!is.na(sentiment)) %>%
count(sentiment, sort = TRUE) %>%
group_by(century) %>%
mutate(n = n/sum(n)) %>%
ggplot(aes(century, n, fill=sentiment))+geom_col(position = 'fill')+
labs(y='Relative Frequency', x ='Century')
##The 21st century has a slightly greater frequency of negative sentiments than the 20th century.##
library(textdata)
df %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(century, word, sort = TRUE) %>%
group_by(century) %>%
inner_join(get_sentiments("nrc")) %>%
filter(!is.na(sentiment)) %>%
count(sentiment, sort = TRUE) %>%
group_by(century) %>%
mutate(n = n/sum(n)) %>%
ggplot(aes(century, n, fill=sentiment))+geom_col(position = 'fill')+
labs(y='Relative Frequency', x ='Century')
#the frequencies are very similar between the two centuries, but the 21st century seems to have less frequency of anger and positive but more negative sentiments overall. ##
df %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(century, word, sort = TRUE) %>%
group_by(century) %>%
inner_join(get_sentiments("afinn")) %>%
mutate(sentiment = value) %>%
filter(!is.na(sentiment)) %>%
count(sentiment, sort = TRUE) %>%
group_by(century) %>%
mutate(n = n/sum(n)) %>%
ggplot(aes(century, n, fill=factor(sentiment)))+geom_col(position = 'dodge')+
labs(y='Relative Frequency', fill = 'Sentiment', x = 'Century')
##This shows the jump in negative sentiments from the 20th to 21st century with a much higher peak at -2.##
library(caret)
library(themis)
library(textrecipes)
df2 <- df %>%
mutate(target = century) %>%
select(target, description)
df2$target = as.factor(df2$target)
a <- recipe(target~description,
data = df2) %>%
step_tokenize(description) %>%
step_tokenfilter(description, max_tokens = 50) %>%
step_tfidf(description) %>%
step_normalize(all_numeric_predictors()) %>%
step_smote(target) %>%
prep()
df2 <- juice(a)
set.seed(2021)
splitIndex <- createDataPartition(df2$target, p = .4,
list = FALSE)
df2_train <- df2[ splitIndex,]
df2_test <- df2[-splitIndex,]
forest_ranger <- train(target~., data=df2_train,
method = "ranger")
